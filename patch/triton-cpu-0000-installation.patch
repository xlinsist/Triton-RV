diff --git a/CMakeLists.txt b/CMakeLists.txt
index 3836abad..ebcedc09 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -25,6 +25,11 @@ option(TRITON_BUILD_UT "Build C++ Triton Unit Tests" ON)
 option(TRITON_BUILD_WITH_CCACHE "Build with ccache (if available)" ON)
 set(TRITON_CODEGEN_BACKENDS "" CACHE STRING "Enable different codegen backends")
 
+set(IS_CPU_ONLY_BUILD 0)
+if(TRITON_CODEGEN_BACKENDS STREQUAL "cpu")
+  set(IS_CPU_ONLY_BUILD 1)
+endif()
+
 if(TRITON_BUILD_WITH_CCACHE)
   find_program(CCACHE_PROGRAM ccache)
   if(CCACHE_PROGRAM)
@@ -202,12 +207,14 @@ if(TRITON_BUILD_PYTHON_MODULE)
     add_subdirectory(third_party/${CODEGEN_BACKEND})
   endforeach()
 
-  if (TRITON_BUILD_PROTON)
-    add_subdirectory(third_party/proton)
+  if(NOT IS_CPU_ONLY_BUILD)
+    if (TRITON_BUILD_PROTON)
+      add_subdirectory(third_party/proton)
+    endif()
+    # We always build proton dialect
+    list(APPEND TRITON_PLUGIN_NAMES "proton")
+    add_subdirectory(third_party/proton/dialect)
   endif()
-  # We always build proton dialect
-  list(APPEND TRITON_PLUGIN_NAMES "proton")
-  add_subdirectory(third_party/proton/dialect)
 
   get_property(triton_libs GLOBAL PROPERTY TRITON_LIBS)
   get_property(triton_plugins GLOBAL PROPERTY TRITON_PLUGINS)
@@ -216,12 +223,6 @@ if(TRITON_BUILD_PYTHON_MODULE)
     ${triton_plugins}
 
     # mlir
-    MLIRAMDGPUDialect
-    MLIRNVVMDialect
-    MLIRNVVMToLLVMIRTranslation
-    MLIRGPUToNVVMTransforms
-    MLIRGPUToGPURuntimeTransforms
-    MLIRGPUTransforms
     MLIRIR
     MLIRControlFlowToLLVM
     MLIRBytecodeWriter
@@ -231,24 +232,33 @@ if(TRITON_BUILD_PYTHON_MODULE)
     MLIRSupport
     MLIRTargetLLVMIRExport
     MLIRMathToLLVM
-    MLIRROCDLToLLVMIRTranslation
-    MLIRGPUDialect
     MLIRSCFToControlFlow
     MLIRIndexToLLVM
-    MLIRGPUToROCDLTransforms
     MLIRUBToLLVM
 
     # LLVM
     LLVMPasses
-    LLVMNVPTXCodeGen
-    # LLVMNVPTXAsmPrinter
-    LLVMAMDGPUCodeGen
-    LLVMAMDGPUAsmParser
 
     Python3::Module
     pybind11::headers
-
   )
+
+  if(NOT IS_CPU_ONLY_BUILD)
+    list(APPEND TRITON_LIBRARIES
+      MLIRAMDGPUDialect
+      MLIRNVVMDialect
+      MLIRNVVMToLLVMIRTranslation
+      MLIRGPUToNVVMTransforms
+      MLIRGPUToGPURuntimeTransforms
+      MLIRGPUTransforms
+      MLIRROCDLToLLVMIRTranslation
+      MLIRGPUDialect
+      MLIRGPUToROCDLTransforms
+      LLVMNVPTXCodeGen
+      LLVMAMDGPUCodeGen
+      LLVMAMDGPUAsmParser
+    )
+  endif()
   if(CMAKE_SYSTEM_PROCESSOR MATCHES "aarch64" OR # Linux arm64
      CMAKE_SYSTEM_PROCESSOR MATCHES "arm64" OR # macOS arm64
      CMAKE_OSX_ARCHITECTURES MATCHES "arm64")  # also macOS arm64
@@ -318,7 +328,9 @@ if(NOT TRITON_BUILD_PYTHON_MODULE)
   foreach(CODEGEN_BACKEND ${TRITON_CODEGEN_BACKENDS})
     add_subdirectory(third_party/${CODEGEN_BACKEND})
   endforeach()
-  add_subdirectory(third_party/proton/dialect)
+  if(NOT IS_CPU_ONLY_BUILD)
+    add_subdirectory(third_party/proton/dialect)
+  endif()
 endif()
 
 find_package(Threads REQUIRED)
@@ -335,4 +347,4 @@ if(TRITON_BUILD_UT)
     DEPENDS TritonUnitTests
     USES_TERMINAL
   )
-endif()
+endif()
\ No newline at end of file
diff --git a/bin/RegisterTritonDialects.h b/bin/RegisterTritonDialects.h
index 41704462..c12aef21 100644
--- a/bin/RegisterTritonDialects.h
+++ b/bin/RegisterTritonDialects.h
@@ -1,30 +1,30 @@
 #pragma once
-#include "amd/include/Dialect/TritonAMDGPU/IR/Dialect.h"
-#include "amd/include/TritonAMDGPUTransforms/Passes.h"
-#include "third_party/nvidia/include/Dialect/NVGPU/IR/Dialect.h"
-#include "third_party/proton/dialect/include/Dialect/Proton/IR/Dialect.h"
+// #include "amd/include/Dialect/TritonAMDGPU/IR/Dialect.h"
+// #include "amd/include/TritonAMDGPUTransforms/Passes.h"
+// #include "third_party/nvidia/include/Dialect/NVGPU/IR/Dialect.h"
+// #include "third_party/proton/dialect/include/Dialect/Proton/IR/Dialect.h"
 #include "triton/Dialect/Triton/IR/Dialect.h"
 #include "triton/Dialect/TritonCPU/IR/Dialect.h"
-#include "triton/Dialect/TritonGPU/IR/Dialect.h"
-#include "triton/Dialect/TritonNvidiaGPU/IR/Dialect.h"
+// #include "triton/Dialect/TritonGPU/IR/Dialect.h"
+// #include "triton/Dialect/TritonNvidiaGPU/IR/Dialect.h"
 
 // Below headers will allow registration to ROCm passes
-#include "TritonAMDGPUToLLVM/Passes.h"
-#include "TritonAMDGPUTransforms/Passes.h"
-#include "TritonAMDGPUTransforms/TritonGPUConversion.h"
+// #include "TritonAMDGPUToLLVM/Passes.h"
+// #include "TritonAMDGPUTransforms/Passes.h"
+// #include "TritonAMDGPUTransforms/TritonGPUConversion.h"
 
 #include "triton/Dialect/Triton/Transforms/Passes.h"
-#include "triton/Dialect/TritonGPU/Transforms/Passes.h"
-#include "triton/Dialect/TritonNvidiaGPU/Transforms/Passes.h"
+// #include "triton/Dialect/TritonGPU/Transforms/Passes.h"
+// #include "triton/Dialect/TritonNvidiaGPU/Transforms/Passes.h"
 
 #include "cpu/include/ScalarizePass/ScalarizeInterfaceImpl.h"
 #include "cpu/include/TritonCPUToLLVM/Passes.h"
 #include "cpu/include/TritonCPUTransforms/Passes.h"
 #include "cpu/include/TritonToTritonCPU/Passes.h"
-#include "nvidia/include/NVGPUToLLVM/Passes.h"
-#include "nvidia/include/TritonNVIDIAGPUToLLVM/Passes.h"
-#include "triton/Conversion/TritonGPUToLLVM/Passes.h"
-#include "triton/Conversion/TritonToTritonGPU/Passes.h"
+// #include "nvidia/include/NVGPUToLLVM/Passes.h"
+// #include "nvidia/include/TritonNVIDIAGPUToLLVM/Passes.h"
+// #include "triton/Conversion/TritonGPUToLLVM/Passes.h"
+// #include "triton/Conversion/TritonToTritonGPU/Passes.h"
 #include "triton/Target/LLVMIR/Passes.h"
 
 #include "mlir/Dialect/AMX/AMXDialect.h"
@@ -44,35 +44,35 @@ void registerTestMembarPass();
 inline void registerTritonDialects(mlir::DialectRegistry &registry) {
   mlir::registerAllPasses();
   mlir::registerTritonPasses();
-  mlir::triton::gpu::registerTritonGPUPasses();
-  mlir::registerTritonNvidiaGPUPasses();
+  // mlir::triton::gpu::registerTritonGPUPasses();
+  // mlir::registerTritonNvidiaGPUPasses();
   mlir::test::registerTestAliasPass();
   mlir::test::registerTestAlignmentPass();
   mlir::test::registerTestAllocationPass();
   mlir::test::registerTestMembarPass();
-  mlir::triton::registerConvertTritonToTritonGPUPass();
-  mlir::triton::registerAllocateSharedMemoryPass();
-  mlir::triton::registerTritonGPUGlobalScratchAllocationPass();
-  mlir::triton::registerConvertTritonGPUToLLVMPass();
-  mlir::triton::registerConvertNVGPUToLLVMPass();
-  mlir::triton::registerDecomposeUnsupportedNVIDIAConversions();
+  // mlir::triton::registerConvertTritonToTritonGPUPass();
+  // mlir::triton::registerAllocateSharedMemoryPass();
+  // mlir::triton::registerTritonGPUGlobalScratchAllocationPass();
+  // mlir::triton::registerConvertTritonGPUToLLVMPass();
+  // mlir::triton::registerConvertNVGPUToLLVMPass();
+  // mlir::triton::registerDecomposeUnsupportedNVIDIAConversions();
   mlir::registerLLVMDIScope();
 
   // TritonAMDGPUToLLVM passes
-  mlir::triton::registerConvertTritonAMDGPUToLLVM();
-  mlir::triton::registerConvertBuiltinFuncToLLVM();
-  mlir::triton::registerDecomposeUnsupportedAMDConversions();
-  mlir::triton::registerOptimizeAMDLDSUsage();
+  // mlir::triton::registerConvertTritonAMDGPUToLLVM();
+  // mlir::triton::registerConvertBuiltinFuncToLLVM();
+  // mlir::triton::registerDecomposeUnsupportedAMDConversions();
+  // mlir::triton::registerOptimizeAMDLDSUsage();
 
   // TritonAMDGPUTransforms passes
-  mlir::registerTritonAMDGPUAccelerateMatmul();
-  mlir::registerTritonAMDGPUOptimizeEpilogue();
-  mlir::registerTritonAMDGPUReorderInstructions();
-  mlir::registerTritonAMDGPUStreamPipeline();
-  mlir::registerTritonAMDGPUCanonicalizePointers();
-  mlir::registerTritonAMDGPUConvertToBufferOps();
-  mlir::triton::registerTritonAMDGPUInsertInstructionSchedHints();
-  mlir::triton::registerTritonAMDGPULowerInstructionSchedHints();
+  // mlir::registerTritonAMDGPUAccelerateMatmul();
+  // mlir::registerTritonAMDGPUOptimizeEpilogue();
+  // mlir::registerTritonAMDGPUReorderInstructions();
+  // mlir::registerTritonAMDGPUStreamPipeline();
+  // mlir::registerTritonAMDGPUCanonicalizePointers();
+  // mlir::registerTritonAMDGPUConvertToBufferOps();
+  // mlir::triton::registerTritonAMDGPUInsertInstructionSchedHints();
+  // mlir::triton::registerTritonAMDGPULowerInstructionSchedHints();
 
   // CPU passes
   mlir::triton::cpu::registerTritonToTritonCPUPasses();
@@ -84,13 +84,13 @@ inline void registerTritonDialects(mlir::DialectRegistry &registry) {
   registry
       .insert<mlir::triton::TritonDialect, mlir::cf::ControlFlowDialect,
               mlir::triton::cpu::TritonCPUDialect,
-              mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect,
-              mlir::triton::gpu::TritonGPUDialect, mlir::math::MathDialect,
+              // mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect,
+              // mlir::triton::gpu::TritonGPUDialect, mlir::math::MathDialect,
               mlir::arith::ArithDialect, mlir::scf::SCFDialect,
               mlir::memref::MemRefDialect, mlir::vector::VectorDialect,
-              mlir::amx::AMXDialect, mlir::tensor::TensorDialect,
-              mlir::gpu::GPUDialect, mlir::LLVM::LLVMDialect,
-              mlir::NVVM::NVVMDialect, mlir::triton::nvgpu::NVGPUDialect,
-              mlir::triton::amdgpu::TritonAMDGPUDialect,
-              mlir::triton::proton::ProtonDialect, mlir::ROCDL::ROCDLDialect>();
+              mlir::amx::AMXDialect, mlir::tensor::TensorDialect>();
+              // mlir::gpu::GPUDialect, mlir::LLVM::LLVMDialect,
+              // mlir::NVVM::NVVMDialect, mlir::triton::nvgpu::NVGPUDialect,
+              // mlir::triton::amdgpu::TritonAMDGPUDialect,
+              // mlir::triton::proton::ProtonDialect, mlir::ROCDL::ROCDLDialect>();
 }
diff --git a/python/setup.py b/python/setup.py
index 5f907472..be9c45f0 100644
--- a/python/setup.py
+++ b/python/setup.py
@@ -294,42 +294,6 @@ def get_thirdparty_packages(packages: list):
     return thirdparty_cmake_args
 
 
-def download_and_copy(name, src_path, dst_path, variable, version, url_func):
-    if is_offline_build():
-        return
-    triton_cache_path = get_triton_cache_path()
-    if variable in os.environ:
-        return
-    base_dir = os.path.dirname(__file__)
-    system = platform.system()
-    try:
-        arch = {"x86_64": "64", "arm64": "aarch64", "aarch64": "aarch64"}[platform.machine()]
-    except KeyError:
-        arch = platform.machine()
-    supported = {"Linux": "linux", "Darwin": "linux"}
-    url = url_func(supported[system], arch, version)
-    tmp_path = os.path.join(triton_cache_path, "nvidia", name)  # path to cache the download
-    dst_path = os.path.join(base_dir, os.pardir, "third_party", "nvidia", "backend", dst_path)  # final binary path
-    platform_name = "sbsa-linux" if arch == "aarch64" else "x86_64-linux"
-    src_path = src_path(platform_name, version) if callable(src_path) else src_path
-    src_path = os.path.join(tmp_path, src_path)
-    download = not os.path.exists(src_path)
-    if os.path.exists(dst_path) and system == "Linux" and shutil.which(dst_path) is not None:
-        curr_version = subprocess.check_output([dst_path, "--version"]).decode("utf-8").strip()
-        curr_version = re.search(r"V([.|\d]+)", curr_version).group(1)
-        download = download or curr_version != version
-    if download:
-        print(f'downloading and extracting {url} ...')
-        file = tarfile.open(fileobj=open_url(url), mode="r|*")
-        file.extractall(path=tmp_path)
-    os.makedirs(os.path.split(dst_path)[0], exist_ok=True)
-    print(f'copy {src_path} to {dst_path} ...')
-    if os.path.isdir(src_path):
-        shutil.copytree(src_path, dst_path, dirs_exist_ok=True)
-    else:
-        shutil.copy(src_path, dst_path)
-
-
 # ---- cmake extension ----
 
 
@@ -491,7 +455,7 @@ class CMakeBuild(build_ext):
         ]
         cmake_args += [f"-D{option}={os.getenv(option)}" for option in passthrough_args if option in os.environ]
 
-        if check_env_flag("TRITON_BUILD_PROTON", "ON"):  # Default ON
+        if check_env_flag("TRITON_BUILD_PROTON", "OFF"):  # Default OFF
             cmake_args += self.get_proton_cmake_args()
 
         if is_offline_build():
@@ -522,67 +486,67 @@ def get_platform_dependent_src_path(subdir):
 
 
 exe_extension = sysconfig.get_config_var("EXE")
-download_and_copy(
-    name="ptxas", src_path=f"bin/ptxas{exe_extension}", dst_path="bin/ptxas", variable="TRITON_PTXAS_PATH",
-    version=NVIDIA_TOOLCHAIN_VERSION["ptxas"], url_func=lambda system, arch, version:
-    ((lambda version_major, version_minor1, version_minor2:
-      f"https://anaconda.org/nvidia/cuda-nvcc-tools/{version}/download/{system}-{arch}/cuda-nvcc-tools-{version}-0.tar.bz2"
-      if int(version_major) >= 12 and int(version_minor1) >= 5 else
-      f"https://anaconda.org/nvidia/cuda-nvcc/{version}/download/{system}-{arch}/cuda-nvcc-{version}-0.tar.bz2")
-     (*version.split('.'))))
-download_and_copy(
-    name="cuobjdump",
-    src_path=f"bin/cuobjdump{exe_extension}",
-    dst_path="bin/cuobjdump",
-    variable="TRITON_CUOBJDUMP_PATH",
-    version=NVIDIA_TOOLCHAIN_VERSION["cuobjdump"],
-    url_func=lambda system, arch, version:
-    f"https://anaconda.org/nvidia/cuda-cuobjdump/{version}/download/{system}-{arch}/cuda-cuobjdump-{version}-0.tar.bz2",
-)
-download_and_copy(
-    name="nvdisasm",
-    src_path=f"bin/nvdisasm{exe_extension}",
-    dst_path="bin/nvdisasm",
-    variable="TRITON_NVDISASM_PATH",
-    version=NVIDIA_TOOLCHAIN_VERSION["nvdisasm"],
-    url_func=lambda system, arch, version:
-    f"https://anaconda.org/nvidia/cuda-nvdisasm/{version}/download/{system}-{arch}/cuda-nvdisasm-{version}-0.tar.bz2",
-)
-download_and_copy(
-    name="cudacrt", src_path=get_platform_dependent_src_path("include"), dst_path="include",
-    variable="TRITON_CUDACRT_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cudacrt"], url_func=lambda system, arch, version:
-    ((lambda version_major, version_minor1, version_minor2:
-      f"https://anaconda.org/nvidia/cuda-crt-dev_{system}-{arch}/{version}/download/noarch/cuda-crt-dev_{system}-{arch}-{version}-0.tar.bz2"
-      if int(version_major) >= 12 and int(version_minor1) >= 5 else
-      f"https://anaconda.org/nvidia/cuda-nvcc/{version}/download/{system}-{arch}/cuda-nvcc-{version}-0.tar.bz2")
-     (*version.split('.'))))
-download_and_copy(
-    name="cudart", src_path=get_platform_dependent_src_path("include"), dst_path="include",
-    variable="TRITON_CUDART_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cudart"], url_func=lambda system, arch, version:
-    ((lambda version_major, version_minor1, version_minor2:
-      f"https://anaconda.org/nvidia/cuda-cudart-dev_{system}-{arch}/{version}/download/noarch/cuda-cudart-dev_{system}-{arch}-{version}-0.tar.bz2"
-      if int(version_major) >= 12 and int(version_minor1) >= 5 else
-      f"https://anaconda.org/nvidia/cuda-cudart-dev/{version}/download/{system}-{arch}/cuda-cudart-dev-{version}-0.tar.bz2"
-      )(*version.split('.'))))
-download_and_copy(
-    name="cupti", src_path=get_platform_dependent_src_path("include"), dst_path="include",
-    variable="TRITON_CUPTI_INCLUDE_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cupti"],
-    url_func=lambda system, arch, version:
-    ((lambda version_major, version_minor1, version_minor2:
-      f"https://anaconda.org/nvidia/cuda-cupti-dev/{version}/download/{system}-{arch}/cuda-cupti-dev-{version}-0.tar.bz2"
-      if int(version_major) >= 12 and int(version_minor1) >= 5 else
-      f"https://anaconda.org/nvidia/cuda-cupti/{version}/download/{system}-{arch}/cuda-cupti-{version}-0.tar.bz2")
-     (*version.split('.'))))
-download_and_copy(
-    name="cupti", src_path=get_platform_dependent_src_path("lib"), dst_path="lib/cupti",
-    variable="TRITON_CUPTI_LIB_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cupti"], url_func=lambda system, arch, version:
-    ((lambda version_major, version_minor1, version_minor2:
-      f"https://anaconda.org/nvidia/cuda-cupti-dev/{version}/download/{system}-{arch}/cuda-cupti-dev-{version}-0.tar.bz2"
-      if int(version_major) >= 12 and int(version_minor1) >= 5 else
-      f"https://anaconda.org/nvidia/cuda-cupti/{version}/download/{system}-{arch}/cuda-cupti-{version}-0.tar.bz2")
-     (*version.split('.'))))
-
-backends = [*BackendInstaller.copy(["nvidia", "amd", "cpu"]), *BackendInstaller.copy_externals()]
+# download_and_copy(
+#     name="ptxas", src_path=f"bin/ptxas{exe_extension}", dst_path="bin/ptxas", variable="TRITON_PTXAS_PATH",
+#     version=NVIDIA_TOOLCHAIN_VERSION["ptxas"], url_func=lambda system, arch, version:
+#     ((lambda version_major, version_minor1, version_minor2:
+#       f"https://anaconda.org/nvidia/cuda-nvcc-tools/{version}/download/{system}-{arch}/cuda-nvcc-tools-{version}-0.tar.bz2"
+#       if int(version_major) >= 12 and int(version_minor1) >= 5 else
+#       f"https://anaconda.org/nvidia/cuda-nvcc/{version}/download/{system}-{arch}/cuda-nvcc-{version}-0.tar.bz2")
+#      (*version.split('.'))))
+# download_and_copy(
+#     name="cuobjdump",
+#     src_path=f"bin/cuobjdump{exe_extension}",
+#     dst_path="bin/cuobjdump",
+#     variable="TRITON_CUOBJDUMP_PATH",
+#     version=NVIDIA_TOOLCHAIN_VERSION["cuobjdump"],
+#     url_func=lambda system, arch, version:
+#     f"https://anaconda.org/nvidia/cuda-cuobjdump/{version}/download/{system}-{arch}/cuda-cuobjdump-{version}-0.tar.bz2",
+# )
+# download_and_copy(
+#     name="nvdisasm",
+#     src_path=f"bin/nvdisasm{exe_extension}",
+#     dst_path="bin/nvdisasm",
+#     variable="TRITON_NVDISASM_PATH",
+#     version=NVIDIA_TOOLCHAIN_VERSION["nvdisasm"],
+#     url_func=lambda system, arch, version:
+#     f"https://anaconda.org/nvidia/cuda-nvdisasm/{version}/download/{system}-{arch}/cuda-nvdisasm-{version}-0.tar.bz2",
+# )
+# download_and_copy(
+#     name="cudacrt", src_path=get_platform_dependent_src_path("include"), dst_path="include",
+#     variable="TRITON_CUDACRT_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cudacrt"], url_func=lambda system, arch, version:
+#     ((lambda version_major, version_minor1, version_minor2:
+#       f"https://anaconda.org/nvidia/cuda-crt-dev_{system}-{arch}/{version}/download/noarch/cuda-crt-dev_{system}-{arch}-{version}-0.tar.bz2"
+#       if int(version_major) >= 12 and int(version_minor1) >= 5 else
+#       f"https://anaconda.org/nvidia/cuda-nvcc/{version}/download/{system}-{arch}/cuda-nvcc-{version}-0.tar.bz2")
+#      (*version.split('.'))))
+# download_and_copy(
+#     name="cudart", src_path=get_platform_dependent_src_path("include"), dst_path="include",
+#     variable="TRITON_CUDART_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cudart"], url_func=lambda system, arch, version:
+#     ((lambda version_major, version_minor1, version_minor2:
+#       f"https://anaconda.org/nvidia/cuda-cudart-dev_{system}-{arch}/{version}/download/noarch/cuda-cudart-dev_{system}-{arch}-{version}-0.tar.bz2"
+#       if int(version_major) >= 12 and int(version_minor1) >= 5 else
+#       f"https://anaconda.org/nvidia/cuda-cudart-dev/{version}/download/{system}-{arch}/cuda-cudart-dev-{version}-0.tar.bz2"
+#       )(*version.split('.'))))
+# download_and_copy(
+#     name="cupti", src_path=get_platform_dependent_src_path("include"), dst_path="include",
+#     variable="TRITON_CUPTI_INCLUDE_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cupti"],
+#     url_func=lambda system, arch, version:
+#     ((lambda version_major, version_minor1, version_minor2:
+#       f"https://anaconda.org/nvidia/cuda-cupti-dev/{version}/download/{system}-{arch}/cuda-cupti-dev-{version}-0.tar.bz2"
+#       if int(version_major) >= 12 and int(version_minor1) >= 5 else
+#       f"https://anaconda.org/nvidia/cuda-cupti/{version}/download/{system}-{arch}/cuda-cupti-{version}-0.tar.bz2")
+#      (*version.split('.'))))
+# download_and_copy(
+#     name="cupti", src_path=get_platform_dependent_src_path("lib"), dst_path="lib/cupti",
+#     variable="TRITON_CUPTI_LIB_PATH", version=NVIDIA_TOOLCHAIN_VERSION["cupti"], url_func=lambda system, arch, version:
+#     ((lambda version_major, version_minor1, version_minor2:
+#       f"https://anaconda.org/nvidia/cuda-cupti-dev/{version}/download/{system}-{arch}/cuda-cupti-dev-{version}-0.tar.bz2"
+#       if int(version_major) >= 12 and int(version_minor1) >= 5 else
+#       f"https://anaconda.org/nvidia/cuda-cupti/{version}/download/{system}-{arch}/cuda-cupti-{version}-0.tar.bz2")
+#      (*version.split('.'))))
+
+backends = [*BackendInstaller.copy(["cpu"]), *BackendInstaller.copy_externals()]
 
 
 def add_link_to_backends():
@@ -607,7 +571,7 @@ def add_link_to_proton():
 
 def add_links():
     add_link_to_backends()
-    if check_env_flag("TRITON_BUILD_PROTON", "ON"):  # Default ON
+    if check_env_flag("TRITON_BUILD_PROTON", "OFF"):  # Default OFF
         add_link_to_proton()
 
 
@@ -681,7 +645,7 @@ def get_packages():
     ]
     packages += [f'triton/backends/{backend.name}' for backend in backends]
     packages += get_language_extra_packages()
-    if check_env_flag("TRITON_BUILD_PROTON", "ON"):  # Default ON
+    if check_env_flag("TRITON_BUILD_PROTON", "OFF"):  # Default OFF
         packages += ["triton/profiler"]
 
     return packages
@@ -689,7 +653,7 @@ def get_packages():
 
 def get_entry_points():
     entry_points = {}
-    if check_env_flag("TRITON_BUILD_PROTON", "ON"):  # Default ON
+    if check_env_flag("TRITON_BUILD_PROTON", "OFF"):  # Default OFF
         entry_points["console_scripts"] = [
             "proton-viewer = triton.profiler.viewer:main",
             "proton = triton.profiler.proton:main",
diff --git a/test/lib/Analysis/TestMembar.cpp b/test/lib/Analysis/TestMembar.cpp
index 25e8e2d1..0f82c414 100644
--- a/test/lib/Analysis/TestMembar.cpp
+++ b/test/lib/Analysis/TestMembar.cpp
@@ -1,4 +1,4 @@
-#include "../third_party/nvidia/include/TritonNVIDIAGPUToLLVM/Utility.h"
+// #include "../third_party/nvidia/include/TritonNVIDIAGPUToLLVM/Utility.h"
 #include "mlir/Conversion/SCFToControlFlow/SCFToControlFlow.h"
 #include "mlir/Dialect/GPU/IR/GPUDialect.h"
 #include "mlir/IR/Dialect.h"
@@ -26,8 +26,8 @@ struct TestMembarPass
     ModuleOp moduleOp = cast<ModuleOp>(operation);
     // Print all ops after membar pass
     ModuleAllocation allocation(moduleOp);
-    ModuleMembarAnalysis membarPass(&allocation,
-                                    mlir::triton::NVIDIA::canSkipBarSync);
+    ModuleMembarAnalysis membarPass(&allocation,                                    
+                                    [](Operation*, Operation*) { return false; });
     membarPass.run();
   }
 };
diff --git a/third_party/amd/backend/compiler.py b/third_party/amd/backend/compiler.py
index 81b07f2e..667a0f57 100644
--- a/third_party/amd/backend/compiler.py
+++ b/third_party/amd/backend/compiler.py
@@ -1,5 +1,5 @@
 from triton.backends.compiler import BaseBackend, GPUTarget, AttrsDescriptor, register_descriptor
-from triton._C.libtriton import ir, passes, llvm, amd
+from triton._C.libtriton import ir, passes, llvm
 from dataclasses import dataclass
 from typing import Any, Dict, Tuple
 from types import ModuleType
diff --git a/third_party/nvidia/backend/compiler.py b/third_party/nvidia/backend/compiler.py
index d94be938..623b2d0b 100644
--- a/third_party/nvidia/backend/compiler.py
+++ b/third_party/nvidia/backend/compiler.py
@@ -1,5 +1,5 @@
 from triton.backends.compiler import BaseBackend, GPUTarget
-from triton._C.libtriton import ir, passes, llvm, nvidia
+from triton._C.libtriton import ir, passes, llvm
 from triton.runtime.errors import PTXASError
 
 from dataclasses import dataclass
