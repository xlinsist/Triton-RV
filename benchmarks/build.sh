#!/bin/bash

# This script builds the Triton benchmarks. It handles code generation for Triton
# kernels, compilation, and linking against the necessary libraries.

# Get the directory of the current script.
DIR=$(dirname "$(readlink -f "$0")")

# ==========================================
# 1. Load Global Configuration
# ==========================================
if [ ! -f "${DIR}/global_config.sh" ]; then
  echo "Error: global_config.sh not found!"
  exit 1
fi
source "${DIR}/global_config.sh"

# Allow command-line arguments to override settings from global_config.sh
DO_CLEAN=${DO_CLEAN:-$DEFAULT_DO_CLEAN}
IFS=' ' read -r -a BENCHMARKS <<< "$BENCHMARKS_LIST"

echo "--------------------------------------------------"
echo "Platform:     $PLATFORM"
echo "Benchmarks:   ${BENCHMARKS[@]}"
echo "Clean Build:  $DO_CLEAN"
echo "Compilers:    Triton (others disabled in this script)"
echo "--------------------------------------------------"

# ==========================================
# 2. User Interface (Help & Argument Parsing)
# ==========================================
help() {
cat <<END
Build script for Triton-only benchmarks.

Usage: ./build.sh [options]

Options:
  --clean | --no-clean    Force a clean or non-clean build.
                          (Default: $DEFAULT_DO_CLEAN)
  --platform <arch>       Override the target platform: 'x86' or 'rv'.
                          (Default: $PLATFORM)
  --help, -h              Print this help message.
END
}

while [ $# -gt 0 ]; do
    case $1 in
        --clean | --no-clean) DO_CLEAN=$1 ;;
        --help | -h) help; exit 0 ;;
        --platform)
            if [ -n "$2" ]; then PLATFORM=$2; shift; else echo "Error: --platform requires an argument."; exit 1; fi ;;
        *) echo "Invalid option: \"$1\". Use --help for usage." >&2; exit 1 ;;
    esac
    shift
done

# ==========================================
# 3. Toolchain Configuration
# ==========================================
# Configure toolchain paths based on the selected platform.
echo "Configuring toolchain for $PLATFORM..."

AR="${LLVM_BUILD_DIR}/bin/llvm-ar"
AS="${LLVM_BUILD_DIR}/bin/llvm-as"

case $PLATFORM in
    x86)
      CXX="${CLANG_BUILD_DIR}/bin/clang++ ${X86_FLAGS} ${CPP_STD}"
      OBJDUMP="${GCC_X86_BUILD_DIR}/bin/objdump"
      ;;
    rv)
      CXX="${CLANG_BUILD_DIR}/bin/clang++ --target=riscv64-unknown-linux-gnu \
              --sysroot=${RISCV_GNU_TOOLCHAIN_DIR}/sysroot \
              --gcc-toolchain=${RISCV_GNU_TOOLCHAIN_DIR} \
              ${RV_FLAGS} ${CPP_STD}"
      OBJDUMP="${RISCV_GNU_TOOLCHAIN_DIR}/bin/riscv64-unknown-linux-gnu-objdump"
      ;;
    *)
      echo "Error: Unknown platform option: $PLATFORM"
      exit 1
      ;;
esac

# ==========================================
# 4. Core Build Functions
# ==========================================

# Compiles the common support library (libsupport.a).
build_support_lib() {
  local obj_dir=$1
  local lib_dir=$2
  
  echo "  -> Building support library..."
  ${CXX} -fPIC -I "${DIR}/include" -c "${SRC_DIR}/support/support.cpp" -o "${obj_dir}/support.o"
  ${OBJDUMP} -d "${obj_dir}/support.o" &> "${obj_dir}/support.s"
  ${AR} rcs "${lib_dir}/libsupport.a" "${obj_dir}/support.o"
}

# Generates, compiles, and links a full Triton benchmark.
build_triton_benchmark() {
  local benchmark_name=$1
  local triton_kernel_file=$2
  local driver_file=$3
  local tunning_arg=$4

  # Define build directory structure.
  local type="triton"
  local lib_dir="${BUILD_DIR}/lib/${type}"
  local bin_dir="${BUILD_DIR}/bin/${type}"
  local obj_dir="${BUILD_DIR}/obj/${type}"
  
  # Paths for files generated by the Triton Python script.
  local kernel_launcher_include_dir="${BUILD_DIR}/aux/include"
  local kernel_aux_file_dir="${BUILD_DIR}/aux/src/${tunning_arg}"

  # Clean previous build artifacts if requested.
  if [ "x$DO_CLEAN" = "x--clean" ]; then
    echo "  -> Cleaning previous build artifacts..."
    rm -rf "${bin_dir}" "${lib_dir}" "${obj_dir}"
    rm -rf "${BUILD_DIR}/aux/"
  fi

  # Create necessary directories for the build process.
  mkdir -p "${lib_dir}" "${bin_dir}" "${obj_dir}" "${kernel_launcher_include_dir}" "${kernel_aux_file_dir}"
  
  # For RISC-V, copy the OpenMP libraries to the library directory.
  if [ "${PLATFORM}" == "rv" ] && [ -d "./openmp-sysroot-riscv/lib" ]; then
    cp ./openmp-sysroot-riscv/lib/* "${lib_dir}"
  fi

  # 1. Compile the common support library.
  build_support_lib "${obj_dir}" "${lib_dir}"

  # 2. Generate intermediate kernel code using the Triton Python script.
  echo "  -> Generating kernels from ${triton_kernel_file}..."
  
  ENABLE_AUTOTUNING=${tunning_arg} \
  KERNEL_LAUNCHER_INCLUDE_DIR=${kernel_launcher_include_dir} \
  KERNEL_AUX_FILE_DIR=${kernel_aux_file_dir} \
  "${PYTHON_EXECUTABLE}" "${triton_kernel_file}"

  local kernel_cpp_name
  kernel_cpp_name=$(basename "${driver_file}" .cpp)
  local kernel_py_name
  kernel_py_name=$(basename "${triton_kernel_file}" .py)
  [[ "$kernel_cpp_name" == "$kernel_py_name" ]] || { echo "Error: Mismatch between driver name (${kernel_cpp_name}) and kernel script name (${kernel_py_name})."; exit 1; }
  
  local kernel_bin_dir="${bin_dir}/${kernel_py_name}"
  mkdir -p "${kernel_bin_dir}"

  # Copy the benchmark-specific configuration (e.g., shapes) to the output directory.
  cp "${SRC_DIR}/main/${kernel_py_name}.cfg" "${kernel_bin_dir}"

  # 3. Compile the generated C++/IR files in parallel.
  echo "  -> Compiling generated kernels and linking into executables..."
  
  # Set up a semaphore for managing parallel jobs.
  local fifo_path="/tmp/fd1_triton_$$"
  mkfifo "${fifo_path}"
  exec 6<>"${fifo_path}"
  rm -f "${fifo_path}"
  for ((i=1; i<=$MAX_MULTITHREADING; i++)); do echo >&6; done

  # Process each directory of generated code (one per tuning configuration).
  shopt -s nullglob # Prevent errors if no matches are found
  for tunning_dir in ${kernel_aux_file_dir}_*; do
    read -u6
    {
        local block_shape
        block_shape=${tunning_dir#*${tunning_arg}_}
        local current_obj_dir="${obj_dir}/${kernel_py_name}_${tunning_arg}_${block_shape}"
        mkdir -p "${current_obj_dir}"
        
        # This is a workaround for certain Triton-generated IR.
        sed -i 's/trunc nuw nsw/trunc/g; s/trunc nuw/trunc/g; s/trunc nsw/trunc/g' "${tunning_dir}"/*.llir

        # A. Compile LLVM IR (.llir) to object files (.o).
        for kernel_ir in "${tunning_dir}"/*.llir; do
            local kname
            kname=$(basename "${kernel_ir}" .llir)
            ${AS} -o "${kernel_aux_file_dir}_${block_shape}/${kname}.bc" "${kernel_ir}"
            ${CXX} -c "${kernel_aux_file_dir}_${block_shape}/${kname}.bc" \
                -o "${current_obj_dir}/${kname}.o"
            ${OBJDUMP} -d "${current_obj_dir}/${kname}.o" \
                 &> "${kernel_aux_file_dir}_${block_shape}/${kname}.s"
        done

        # B. Compile the C++ launcher to an object file.
        for kernel_launcher in "${tunning_dir}"/*.cpp; do
            local lname
            lname=$(basename "${kernel_launcher}" .cpp)
            ${CXX} -I "${DIR}/include" -I "${kernel_launcher_include_dir}" -c "${kernel_launcher}" \
                -fopenmp -o "${current_obj_dir}/${lname}.o"
        done

        # C. Archive all generated object files into a static library.
        find "${current_obj_dir}/" -not -name "support.o" -name "*.o" | \
            xargs ${AR} rcs "${lib_dir}/libkernel_${tunning_arg}_${block_shape}.a"
        
        # D. Link the driver with the libraries to create the final executable.
        ${CXX} "${driver_file}" -I "${DIR}/include" -I "${kernel_launcher_include_dir}" \
            -L "${lib_dir}" -fopenmp -L"${CLANG_BUILD_DIR}/lib" \
            -lkernel_${tunning_arg}_${block_shape} -lsupport -latomic \
            ${CPP_STD} -DTRITON_KERNEL_ENABLE -fPIC \
            -o "${kernel_bin_dir}/${kernel_py_name}_${tunning_arg}_${block_shape}.elf"
        
        # Release the semaphore lock.
        echo >&6
    } &
  done
  wait
  exec 6>&-
  shopt -u nullglob
}

# ==========================================
# 5. Main Execution Loop
# ==========================================

for BENCHMARK in "${BENCHMARKS[@]}"; do
  echo ">>> Processing Benchmark: $BENCHMARK"

  # Configure paths for the current benchmark.
  TRITON_KERNEL="${SRC_DIR}/triton/${BENCHMARK}.py"
  DRIVER="${SRC_DIR}/main/${BENCHMARK}.cpp"

  # Map benchmark name to the internal kernel/tuning name used in the Python scripts.
  case "$BENCHMARK" in
    "add")         TUNNING_ARG="add" ;;
    "matmul")      TUNNING_ARG="matmul_kernel" ;;
    "softmax")     TUNNING_ARG="softmax_kernel" ;;
    "layernorm")   TUNNING_ARG="_layer_norm_fwd_fused" ;;
    "correlation") TUNNING_ARG="correlation_kernel" ;;
    "dropout")     TUNNING_ARG="dropout_kernel" ;;
    "resize")      TUNNING_ARG="resize_kernel" ;;
    "rope")        TUNNING_ARG="rope_kernel" ;;
    "warp")        TUNNING_ARG="warp_kernel" ;;
    *) 
       echo "Warning: Unknown benchmark '$BENCHMARK', assuming kernel name is '${BENCHMARK}_kernel'"
       TUNNING_ARG="${BENCHMARK}_kernel"
       ;;
  esac

  # Check if the required source files exist before attempting to build.
  if [[ ! -f "$TRITON_KERNEL" ]]; then
     echo "Error: Triton kernel file for $BENCHMARK not found at $TRITON_KERNEL. Skipping."
     continue
  fi
  if [[ ! -f "$DRIVER" ]]; then
     echo "Error: Driver file for $BENCHMARK not found at $DRIVER. Skipping."
     continue
  fi

  # Set the root build directory for the current benchmark.
  BUILD_DIR="${DIR}/build-${BENCHMARK}"
  
  # Execute the build process for this benchmark.
  build_triton_benchmark "$BENCHMARK" "$TRITON_KERNEL" "$DRIVER" "$TUNNING_ARG"

  echo "<<< Finished Benchmark: $BENCHMARK"
  echo ""
done

echo "Build process completed."
